{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 12)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<tokenize>\"\u001b[0;36m, line \u001b[0;32m12\u001b[0m\n\u001b[0;31m    for i in range(n_state):\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.linalg\n",
    "# import matplotlib.pyplot as plt\n",
    "# import scipy.linalg.hadamard as hadamard\n",
    "\n",
    "def get_mc_traj(len):\n",
    "    n_state = 9 # 1,2,3...9\n",
    "    p = np.ndarray([n_state,n_state])\n",
    "    p_gt = np.ndarray([n_state,n_state])\n",
    "    for i in range(n_state):\n",
    "        for j in range(n_state):\n",
    "            if j == 0:\n",
    "                p[i,j] =  np.exp(-(i+1))*np.exp(-(j+1)) + 2*(1-np.exp(-(i+1)))*np.exp(-2*(j+1))\n",
    "                p_gt[i,j] =  p[i,j]\n",
    "            else:\n",
    "                p_gt[i,j] = np.exp(-(i+1))*np.exp(-(j+1)) + 2*(1-np.exp(-(i+1)))*np.exp(-2*(j+1)) #\n",
    "                p[i,j] = p[i,j-1] + p_gt[i,j]\n",
    "        p[i,:] = p[i,:] / p[i,n_state-1]\n",
    "\n",
    "    print(\"p\",p_gt)\n",
    "    traj = np.ndarray([1,len])\n",
    "    s = 0\n",
    "    traj[0] = s\n",
    "    counter = 0\n",
    "    for i in range(len):\n",
    "    s = get_next_state(s,p)\n",
    "    traj[:,i] = s + 1\n",
    "    if s is not 0:\n",
    "      counter += 1\n",
    "    print(counter)\n",
    "    return traj, p_gt\n",
    "    \n",
    "def get_next_state(i,p):\n",
    "    prob = np.random.rand()\n",
    "    for j in range(len(p[0])):\n",
    "        if prob < p[i,j]:\n",
    "            return j\n",
    "    return j\n",
    "\n",
    "def brownian_motion(len):\n",
    "    dt = 0.01\n",
    "    p = np.array([10.0,10.0])\n",
    "    traj = np.ndarray([2,len])\n",
    "    for i in range(len):\n",
    "        p += np.sqrt(dt) * np.random.normal(loc=0.0,scale=1.0,size = 2)\n",
    "        traj[:,i] = p\n",
    "    print(traj)\n",
    "    return traj\n",
    "\n",
    "def normalize(rrf):\n",
    "    norm = np.linalg.norm(rrf)\n",
    "    norm_rrf = rrf/norm\n",
    "    return norm_rrf\n",
    "\n",
    "def Get_p_(p_hat,r,c_12):\n",
    "    p_ = np.empty_like(p_hat)\n",
    "    p_hat[0] = np.dot(np.dot(c_12,p_hat[0]),c_12)\n",
    "    for i in range(len(p_hat)):\n",
    "        u, s, vh = np.linalg.svd(p_hat[i], full_matrices=True)\n",
    "        u_ = u[:,:r]\n",
    "        s_ = np.diag(s[:r])\n",
    "\n",
    "        vh_ = vh[:r,:]\n",
    "        # print(\"s_: \",s_)\n",
    "        p_[i] = np.dot(np.dot(u_,s_),vh_)\n",
    "        # print(\"p_[1]\", p_[1])\n",
    "        # print(\"p_[2]\", p_[2])\n",
    "        # print(\"p_[3]\", p_[3])\n",
    "\n",
    "    return p_\n",
    "\n",
    "def Get_P_hat(traj,G, w_orf, w_sorf,step=1):\n",
    "    avg = np.ndarray((2,n_feature,n_feature))\n",
    "    i = 0\n",
    "    counter = 0\n",
    "    # print(len(traj))\n",
    "    while i+step < len(traj[0]):\n",
    "        if i % 1000 == 0:\n",
    "            print(\"i\",i)\n",
    "        x = traj[:,i]\n",
    "\n",
    "        y = traj[:,i+step]\n",
    "        k_orf, k_sorf = Kernel(x,y,G, w_orf, w_sorf)\n",
    "\n",
    "        # avg[0] += k_rff_1\n",
    "        # avg[0] += k_rff_2\n",
    "        avg[0] += k_orf\n",
    "        avg[1] += k_sorf\n",
    "        i += step\n",
    "        counter += 1\n",
    "    avg = avg/counter\n",
    "    # print(\"p_hat\",avg)\n",
    "    return avg\n",
    "\n",
    "def Kernel(x,y,G,w_orf,w_sorf):\n",
    "    # rff_1_x = RFF_1(x,w,n)\n",
    "    # rff_1_y = RFF_1(y,w,n)\n",
    "    # k_rff_1 = np.dot(rff_1_x.transpose(),rff_1_y)\n",
    "    # print(\"rff_1_x\", rff_1_x)\n",
    "    # print(\"rff_1_y.shape\", rff_1_y.shape)\n",
    "    # rff_2_x = RFF_2(x,G)\n",
    "    # rff_2_y = RFF_2(y,G)\n",
    "    # k_rff_2 = np.dot(rff_2_x.transpose(),rff_2_y)\n",
    "    # print(\"rff_2_x\", rff_2_x)\n",
    "    # print(\"rff_2_y.shape\", rff_2_y.shape)\n",
    "\n",
    "    orf_x = ORF(x,w_orf)\n",
    "    orf_y = ORF(y,w_orf)\n",
    "    k_orf = np.dot(orf_x.transpose(),orf_y)\n",
    "    # print(\"orf_x\", orf_x)\n",
    "    # print(\"orf_y.shape\", orf_y.shape)\n",
    "\n",
    "    sorf_x = SORF(x,w_sorf)\n",
    "    sorf_y = SORF(y,w_sorf)\n",
    "    k_sorf = np.dot(sorf_x.transpose(),sorf_y)\n",
    "    # print(\"sorf_x\", sorf_x)\n",
    "    # print(\"sorf_y.shape\", sorf_y.shape)\n",
    "\n",
    "    # print(\"k_rff_1\", k_rff_1)\n",
    "    # print(\"k_rff_2\", k_rff_2)\n",
    "    # print(\"k_orf\", k_orf)\n",
    "    # print(\"k_sorf\", k_sorf)\n",
    "    return  k_orf, k_sorf  # n * n\n",
    "\n",
    "# random Fourier feature \n",
    "def RFF_1(x,w,n_raw,n_feature):\n",
    "    rff = np.zeros((n_raw,n_feature))\n",
    "    rff[0,:]  = np.sqrt(2.0/n_feature)*(np.sin(w*x[0])) \n",
    "    # q, r = np.linalg.qr(rff_x)\n",
    "    # print(\"q\",q)\n",
    "    # print(\"r\",r)\n",
    "    rff[1,:] = np.sqrt(2.0/n_feature)*(np.cos(w*x[1]))  # D*1 \n",
    "    return rff  #D*2\n",
    "\n",
    "def RFF_2(x,G):\n",
    "    rff = np.reshape(np.dot(G,x.transpose()),(1,-1))\n",
    "    rff = normalize(rff)\n",
    "    return rff # 2*D\n",
    "\n",
    "def get_w_orf(n_raw,n_feature,G):\n",
    "    w_orf = np.zeros((n_feature,n_raw))\n",
    "    c = np.zeros(n_feature)\n",
    "    for i in range(n_feature//n_raw):\n",
    "        q, r = np.linalg.qr(G[n_raw*i:n_raw*i+n_raw,:])\n",
    "        s = np.random.chisquare(n_raw,size=n_raw)\n",
    "        s_diag = np.diag(s)\n",
    "        # print(\"s\",s_diag)\n",
    "        c[2*i:2*i+2] = 1/np.sqrt(s)\n",
    "\n",
    "\n",
    "        w_orf[2*i:2*i+2] = np.dot(s_diag,q)\n",
    "   \n",
    "    c_diag = np.diag(c)\n",
    "    # print(\"norm\", norm)\n",
    "    # orf = np.dot(w_orf,x.transpose())\n",
    "    return c_diag, w_orf\n",
    "\n",
    "def ORF(x,w_orf):\n",
    "    orf = np.reshape(np.dot(w_orf,x.transpose()),(1,-1))\n",
    "    # print(orf)\n",
    "    return  orf\n",
    "\n",
    "def get_w_sorf(n_raw, n_feature):\n",
    "    H = scipy.linalg.hadamard(n_raw)\n",
    "    # print(\"H\", H)\n",
    "    w_sorf = np.zeros((n_feature,n_raw))\n",
    "    for i in range(n_feature//n_raw):\n",
    "      d1 = np.random.rand(n_raw)\n",
    "      d2 = np.random.rand(n_raw)\n",
    "      d3 = np.random.rand(n_raw)\n",
    "      for element in d1:\n",
    "        if element > 0.5:\n",
    "           element = 1\n",
    "        else:\n",
    "           element = -1\n",
    "      for element in d2:\n",
    "        if element > 0.5:\n",
    "           element = 1\n",
    "        else:\n",
    "           element = -1\n",
    "      for element in d3:\n",
    "        if element > 0.5:\n",
    "           element = 1\n",
    "        else:\n",
    "           element = -1\n",
    "      d1 = np.diag(d1)\n",
    "      d2 = np.diag(d2)\n",
    "      d3 = np.diag(d3)\n",
    "      w_sorf[n_raw*i:n_raw*i+n_raw,:] = np.sqrt(2)*np.dot(np.dot(np.dot(np.dot(np.dot(H,d1),H),d2),H),d3)\n",
    "   \n",
    "    # sorf= normalize(sorf)\n",
    "    return w_sorf\n",
    "def SORF(x,w_sorf):\n",
    "    sorf = np.reshape(np.dot(w_sorf,x),(1,-1))\n",
    "    # sorf= normalize(sorf)\n",
    "    return sorf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# state, action, done = load_record_csv()\n",
    "# traj = brownian_motion(10000)\n",
    "traj, gt_p = get_mc_traj(5000)\n",
    "print(traj)\n",
    "r = 4 # rank\n",
    "n_feature_list = [256] # n features\n",
    "n_raw = 1 # n-dimensional raw data\n",
    "step_list = [1]\n",
    "\n",
    "\n",
    "# n_list = [16] # n features\n",
    "# step_list = [1]\n",
    "# x = np.array([[0],[1],[2]])\n",
    "# y = np.array([[0],[1],[2]])\n",
    "x_list = [np.array([1]),np.array([2]),np.array([3])]\n",
    "y_list = [np.array([1]),np.array([2]),np.array([3])]\n",
    "for n_feature in n_feature_list:\n",
    "    for step in step_list:\n",
    "        print(\"n:\",n_feature)\n",
    "        print(\"step:\",step)\n",
    "        # w for rff_1\n",
    "        w = np.random.normal(loc=0.0, scale=1.0, size=n_feature) # n * 1\n",
    "        # gaussian for rff_2\n",
    "        G = np.random.normal(loc=0.0, scale=1.0, size=(n_feature,n_raw))\n",
    "        c_12 , w_orf = get_w_orf(n_raw,n_feature,G)\n",
    "        w_sorf = get_w_sorf(n_raw,n_feature)\n",
    "        p_hat = Get_P_hat(traj, G , w_orf, w_sorf,step)\n",
    "        # \n",
    "        p_ = Get_p_(p_hat,r,c_12)\n",
    "\n",
    "        # # print(\"p_hat:\",p_hat)\n",
    "        print(\"p_:\",p_)\n",
    "\n",
    "        for x in x_list:\n",
    "            for y in y_list:\n",
    "                orf_x  = ORF(x,w_orf)\n",
    "                # orf_x = normalize(orf_x)\n",
    "                orf_y = ORF(y,w_orf)\n",
    "                # orf_y = normalize(orf_y)\n",
    "                sorf_x = SORF(x,w_sorf)\n",
    "                # sorf_x = normalize(sorf_x)\n",
    "                sorf_y = SORF(y,w_sorf)\n",
    "                # sorf_y = normalize(sorf_y)\n",
    "\n",
    "                # p_rff_1 = np.dot(np.dot(rff_1_x, p_[0]),rff_1_y.transpose())\n",
    "                # p_rff_2 = np.dot(np.dot(rff_2_x, p_[0]),rff_2_y.transpose())\n",
    "                p_orf = np.dot(np.dot(np.dot(np.dot(orf_x,c_12), p_[0]),c_12),orf_y.transpose())\n",
    "                p_sorf = np.dot(np.dot(sorf_x, p_[1]),sorf_y.transpose())\n",
    "\n",
    "                print(\"x\",x)\n",
    "                print(\"y\",y)\n",
    "                # print(\"p_rff_1\", p_rff_1)\n",
    "                # print(\"p_rff_2 \",p_rff_2)\n",
    "                print(\"p_orf\" ,p_orf)\n",
    "                print(\"p_sorf\",p_sorf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
